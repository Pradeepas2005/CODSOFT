# -*- coding: utf-8 -*-
"""Untitled12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1whUb1fdPO8bOt5LIHkRNmgkmB67biYfi
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV, KFold
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import LinearSVC
from sklearn.multioutput import MultiOutputClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.pipeline import Pipeline
from tqdm import tqdm

# Genres extracted from the dataset
genres = [
    'action', 'adult', 'adventure', 'animation', 'biography', 'comedy', 'crime',
    'documentary', 'family', 'fantasy', 'game-show', 'history', 'horror', 'music',
    'musical', 'mystery', 'news', 'reality-tv', 'romance', 'sci-fi', 'short',
    'sport', 'talk-show', 'thriller', 'war', 'western'
]

# Load training data from file
try:
    with tqdm(total=50, desc="Loading Training Data") as progress:
        train_data = pd.read_csv(
            'train_data.txt',
            sep=':::',
            header=None,
            names=['SerialNumber', 'MOVIE_NAME', 'GENRE', 'MOVIE_PLOT'],
            engine='python'
        )
        progress.update(50)
except Exception as err:
    print(f"Failed to load training data: {err}")
    raise

# Preprocess text and labels
X_train = train_data['MOVIE_PLOT'].astype(str).apply(str.lower)
genre_labels = [genre.split(', ') for genre in train_data['GENRE']]
mlb = MultiLabelBinarizer()
y_train = mlb.fit_transform(genre_labels)

# Create a TF-IDF vectorizer
vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))

# Split dataset into training and validation subsets
X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(
    X_train, y_train, test_size=0.2, random_state=42
)

# Build pipeline for model
pipeline = Pipeline([
    ('vectorizer', vectorizer),
    ('classifier', MultiOutputClassifier(LinearSVC()))
])

# Define hyperparameters for tuning
param_grid = {
    'classifier__estimator__C': [1, 10],
    'classifier__estimator__penalty': ['l2'],
    'vectorizer__max_features': [10000, 15000],
    'vectorizer__ngram_range': [(1, 2)]
}

# Use K-Fold cross-validation
kf = KFold(n_splits=5, shuffle=True, random_state=42)

grid_search = GridSearchCV(
    pipeline,
    param_grid,
    cv=kf,
    verbose=2,
    n_jobs=-1,
    scoring='accuracy'
)

# Train model using GridSearch
grid_search.fit(X_train_split, y_train_split)

# Retrieve the best-performing model
best_model = grid_search.best_estimator_

# Predict genres on validation data
predictions = best_model.predict(X_val_split)

# Save predicted results with movie names
results_df = pd.DataFrame({
    'MOVIE_NAME': train_data.iloc[X_val_split.index]['MOVIE_NAME'],
    'PREDICTED_GENRES': mlb.inverse_transform(predictions)
})
results_df.to_csv('predicted_movie_genres.csv', index=False)

# Evaluate model performance
accuracy = accuracy_score(y_val_split, predictions)
precision = precision_score(y_val_split, predictions, average='micro')
recall = recall_score(y_val_split, predictions, average='micro')
f1 = f1_score(y_val_split, predictions, average='micro')

# Output metrics to console
print(f"Accuracy: {accuracy * 100:.2f}%")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1-Score: {f1:.2f}")

# Write evaluation results to a file
with open('model_evaluation.txt', 'w', encoding='utf-8') as file:
    file.write(f"Accuracy: {accuracy * 100:.2f}%\n")
    file.write(f"Precision: {precision:.2f}\n")
    file.write(f"Recall: {recall:.2f}\n")
    file.write(f"F1-Score: {f1:.2f}\n")